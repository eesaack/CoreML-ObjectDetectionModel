{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b771e24b",
   "metadata": {},
   "source": [
    "### <center> PREFERENCES AS BINARY RELATIONS </center>\n",
    "#### <center> MASTER BDMA - DECISION MODELING </center>\n",
    "##### <center> Authors: Dilbar Isakova, MD Kamrul Islam </center>\n",
    "##### <center> Professor: Brice Mayag </center>\n",
    "###### <center> CentraleSupel√©c, Fall, 2024 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c478b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a47df1",
   "metadata": {},
   "source": [
    "#### DataFrame with the movie critics' ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19e93829",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Critic': ['Lisa Rose', 'Gene Seymour', 'Michael Phillips', 'Claudia Puig', 'Mick Lasalle', 'Jack Matthews', 'Toby', 'Anne'],\n",
    "    'Lady': [2.5, 3.0, 2.5, None, 3.0, 3.0, None, 1.5],\n",
    "    'Snakes': [3.5, 3.5, 3.0, 3.5, 4.0, 4.0, 4.5, None],\n",
    "    'Luck': [3.0, 1.5, None, 3.0, 2.0, None, None, 4.0],\n",
    "    'Superman': [3.5, 5.0, 3.5, 4.0, 3.0, 5.0, 4.0, None],\n",
    "    'Dupree': [2.5, 3.5, None, 2.5, 2.0, 3.5, 1.0, 2.0],\n",
    "    'Night': [3.0, 3.0, 4.0, 4.5, 3.0, 3.0, None, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "excel_file_path = 'movie_ratings.xlsx'\n",
    "df.to_excel(excel_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba9c01",
   "metadata": {},
   "source": [
    "## Question 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "429c345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critiques['Lisa Rose']: {'Lady': 2.5, 'Snakes': 3.5, 'Luck': 3.0, 'Superman': 3.5, 'Dupree': 2.5, 'Night': 3.0}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(excel_file_path)\n",
    "df.set_index('Critic', inplace=True)\n",
    "\n",
    "# Transpose and convert to dictionary\n",
    "critiques = df.transpose().to_dict()\n",
    "\n",
    "# Check Lisa Rose's ratings\n",
    "print(\"Critiques['Lisa Rose']:\", critiques['Lisa Rose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a40103",
   "metadata": {},
   "source": [
    "## Question 02(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ebe4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_distanceManhattan(person1, person2):\n",
    "    shared_movies = [\n",
    "        movie for movie in person1\n",
    "        if movie in person2 and not pd.isna(person1[movie]) and not pd.isna(person2[movie])\n",
    "    ]\n",
    "    if not shared_movies:\n",
    "        return float('inf') \n",
    "    # Calculate Manhattan distance\n",
    "    ratings1 = np.array([person1[movie] for movie in shared_movies])\n",
    "    ratings2 = np.array([person2[movie] for movie in shared_movies])\n",
    "    distance = np.sum(np.abs(ratings1 - ratings2))\n",
    "    return distance\n",
    "\n",
    "def sim_distanceEuclidienne(person1, person2):\n",
    "    shared_movies = [\n",
    "        movie for movie in person1\n",
    "        if movie in person2 and not pd.isna(person1[movie]) and not pd.isna(person2[movie])\n",
    "    ]\n",
    "    if not shared_movies:\n",
    "        return float('inf')\n",
    "    # Calculate Euclidean distance\n",
    "    ratings1 = np.array([person1[movie] for movie in shared_movies])\n",
    "    ratings2 = np.array([person2[movie] for movie in shared_movies])\n",
    "    distance = np.sqrt(np.sum((ratings1 - ratings2) ** 2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c2b451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Distance between Lisa Rose and Gene Seymour: 4.5\n",
      "Euclidean Distance between Lisa Rose and Gene Seymour: 2.3979157616563596\n"
     ]
    }
   ],
   "source": [
    "manhattan_distance = sim_distanceManhattan(critiques['Lisa Rose'], critiques['Gene Seymour'])\n",
    "euclidean_distance = sim_distanceEuclidienne(critiques['Lisa Rose'], critiques['Gene Seymour'])\n",
    "\n",
    "print(\"Manhattan Distance between Lisa Rose and Gene Seymour:\", manhattan_distance)\n",
    "print(\"Euclidean Distance between Lisa Rose and Gene Seymour:\", euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8f2de",
   "metadata": {},
   "source": [
    "## Question 02(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30b6d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNearestNeighbor(nouveauCritique, critiques):\n",
    "    distances = []\n",
    "    for critique in critiques:\n",
    "        if critique != nouveauCritique:\n",
    "            distance = sim_distanceManhattan(critiques[critique], critiques[nouveauCritique])\n",
    "            distances.append((distance, critique))\n",
    "    distances.sort()\n",
    "    return distances\n",
    "\n",
    "def recommendNearestNeighbor(nouveauCritique, critiques):\n",
    "\n",
    "    nearest = computeNearestNeighbor(nouveauCritique, critiques)\n",
    "    for distance, neighbor in nearest:\n",
    "        neighbor_ratings = critiques[neighbor]\n",
    "        user_ratings = critiques[nouveauCritique]\n",
    "        recommendations = []\n",
    "        for movie in neighbor_ratings:\n",
    "            if (movie not in user_ratings or pd.isna(user_ratings[movie])) and not pd.isna(neighbor_ratings[movie]):\n",
    "                recommendations.append((movie, neighbor_ratings[movie]))\n",
    "        if recommendations:\n",
    "            return recommendations\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21807102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors for 'Lisa Rose':\n",
      "[(1.5, 'Michael Phillips'), (2.0, 'Claudia Puig'), (2.5, 'Anne'), (3.0, 'Mick Lasalle'), (3.0, 'Toby'), (3.5, 'Jack Matthews'), (4.5, 'Gene Seymour')]\n",
      "\n",
      "Recommendations for 'Lisa Rose':\n",
      "[]\n",
      "\n",
      "Nearest neighbors for 'Toby':\n",
      "[(1.0, 'Anne'), (2.0, 'Michael Phillips'), (2.5, 'Claudia Puig'), (2.5, 'Mick Lasalle'), (3.0, 'Lisa Rose'), (4.0, 'Jack Matthews'), (4.5, 'Gene Seymour')]\n",
      "\n",
      "Recommendations for 'Toby':\n",
      "[('Lady', 1.5), ('Luck', 4.0)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Nearest neighbors for 'Lisa Rose':\")\n",
    "print(computeNearestNeighbor('Lisa Rose', critiques))\n",
    "print(\"\\nRecommendations for 'Lisa Rose':\")\n",
    "print(recommendNearestNeighbor('Lisa Rose', critiques))\n",
    "\n",
    "print(\"\\nNearest neighbors for 'Toby':\")\n",
    "print(computeNearestNeighbor('Toby', critiques))\n",
    "print(\"\\nRecommendations for 'Toby':\")\n",
    "print(recommendNearestNeighbor('Toby', critiques))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a62a3",
   "metadata": {},
   "source": [
    "## Question 2(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c8eb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestrecommend function\n",
    "def Bestrecommend(nouveauCritique, critiques, movies_to_consider, distance_metric):\n",
    "    totals = {}\n",
    "    sim_sums = {}\n",
    "    for movie in movies_to_consider:\n",
    "        totals[movie] = 0.0\n",
    "        sim_sums[movie] = 0.0\n",
    "\n",
    "    for critic in critiques:\n",
    "        if critic == nouveauCritique:\n",
    "            continue\n",
    "        distance = distance_metric(critiques[critic], critiques[nouveauCritique])\n",
    "        if distance == float('inf'):\n",
    "            continue \n",
    "        weight = 1 / (1 + distance)\n",
    "        if weight <= 0:\n",
    "            continue \n",
    "        for movie in movies_to_consider:\n",
    "            # Only consider movies that critic has rated and Anne hasn't\n",
    "            if movie in critiques[critic] and not pd.isna(critiques[critic][movie]):\n",
    "                if movie not in critiques[nouveauCritique] or pd.isna(critiques[nouveauCritique][movie]):\n",
    "                    totals[movie] += critiques[critic][movie] * weight\n",
    "                    sim_sums[movie] += weight\n",
    "\n",
    "    rankings = []\n",
    "    for movie in movies_to_consider:\n",
    "        if sim_sums[movie] != 0:\n",
    "            score = totals[movie] / sim_sums[movie]\n",
    "            rankings.append((round(score, 2), movie))\n",
    "    rankings.sort(reverse=True)\n",
    "    return rankings\n",
    "\n",
    "\n",
    "# BestrecommendwithExp function\n",
    "def BestrecommendwithExp(nouveauCritique, critiques, movies_to_consider, distance_metric):\n",
    "    totals = {}\n",
    "    sim_sums = {}\n",
    "    for movie in movies_to_consider:\n",
    "        totals[movie] = 0.0\n",
    "        sim_sums[movie] = 0.0\n",
    "\n",
    "    for critic in critiques:\n",
    "        if critic == nouveauCritique:\n",
    "            continue\n",
    "        distance = distance_metric(critiques[critic], critiques[nouveauCritique])\n",
    "        if distance == float('inf'):\n",
    "            continue \n",
    "        weight = np.exp(-distance)\n",
    "        if weight <= 0:\n",
    "            continue \n",
    "        for movie in movies_to_consider:\n",
    "            # Only consider movies that critic has rated and Anne hasn't\n",
    "            if movie in critiques[critic] and not pd.isna(critiques[critic][movie]):\n",
    "                if movie not in critiques[nouveauCritique] or pd.isna(critiques[nouveauCritique][movie]):\n",
    "                    totals[movie] += critiques[critic][movie] * weight\n",
    "                    sim_sums[movie] += weight\n",
    "\n",
    "    rankings = []\n",
    "    for movie in movies_to_consider:\n",
    "        if sim_sums[movie] != 0:\n",
    "            score = totals[movie] / sim_sums[movie]\n",
    "            rankings.append((score, movie))\n",
    "    rankings.sort(reverse=True)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27b861ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recommendations for Anne using Manhattan distance:\n",
      "Movie: Superman, Predicted Rating: 3.91\n",
      "Movie: Snakes, Predicted Rating: 3.71\n",
      "Movie: Night, Predicted Rating: 3.61\n",
      "\n",
      "Best recommendations for Anne using Euclidean distance:\n",
      "Movie: Superman, Predicted Rating: 3.93\n",
      "Movie: Snakes, Predicted Rating: 3.70\n",
      "Movie: Night, Predicted Rating: 3.55\n",
      "\n",
      "Best recommendations for Anne using Manhattan distance with exponential weights:\n",
      "Movie: Night, Predicted Rating: 3.93\n",
      "Movie: Superman, Predicted Rating: 3.82\n",
      "Movie: Snakes, Predicted Rating: 3.70\n",
      "\n",
      "Best recommendations for Anne using Euclidean distance with exponential weights:\n",
      "Movie: Superman, Predicted Rating: 3.86\n",
      "Movie: Night, Predicted Rating: 3.74\n",
      "Movie: Snakes, Predicted Rating: 3.69\n"
     ]
    }
   ],
   "source": [
    "# Movies to consider\n",
    "movies_to_consider = ['Snakes', 'Superman', 'Night']\n",
    "\n",
    "print(\"Best recommendations for Anne using Manhattan distance:\")\n",
    "manhattan_recommendations = Bestrecommend('Anne', critiques, movies_to_consider, sim_distanceManhattan)\n",
    "for score, movie in manhattan_recommendations:\n",
    "    print(f\"Movie: {movie}, Predicted Rating: {score:.2f}\")\n",
    "\n",
    "print(\"\\nBest recommendations for Anne using Euclidean distance:\")\n",
    "euclidean_recommendations = Bestrecommend('Anne', critiques, movies_to_consider, sim_distanceEuclidienne)\n",
    "for score, movie in euclidean_recommendations:\n",
    "    print(f\"Movie: {movie}, Predicted Rating: {score:.2f}\")\n",
    "\n",
    "print(\"\\nBest recommendations for Anne using Manhattan distance with exponential weights:\")\n",
    "exp_manhattan_recommendations = BestrecommendwithExp('Anne', critiques, movies_to_consider, sim_distanceManhattan)\n",
    "for score, movie in exp_manhattan_recommendations:\n",
    "    print(f\"Movie: {movie}, Predicted Rating: {score:.2f}\")\n",
    "\n",
    "print(\"\\nBest recommendations for Anne using Euclidean distance with exponential weights:\")\n",
    "exp_euclidean_recommendations = BestrecommendwithExp('Anne', critiques, movies_to_consider, sim_distanceEuclidienne)\n",
    "for score, movie in exp_euclidean_recommendations:\n",
    "    print(f\"Movie: {movie}, Predicted Rating: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36887a3b",
   "metadata": {},
   "source": [
    "## Question 2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4c59820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation function\n",
    "def pearson(person1, person2):\n",
    "    sum_xy = 0\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    sum_x2 = 0\n",
    "    sum_y2 = 0\n",
    "    n = 0\n",
    "    for key in person1:\n",
    "        if key in person2:\n",
    "            x = person1[key]\n",
    "            y = person2[key]\n",
    "            if not pd.isna(x) and not pd.isna(y):\n",
    "                n += 1\n",
    "                sum_xy += x * y\n",
    "                sum_x += x\n",
    "                sum_y += y\n",
    "                sum_x2 += x**2\n",
    "                sum_y2 += y**2\n",
    "    if n == 0:\n",
    "        return 0  # No ratings in common\n",
    "    denominator = sqrt(sum_x2 - (sum_x**2) / n) * sqrt(sum_y2 - (sum_y**2) / n)\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        numerator = sum_xy - (sum_x * sum_y) / n\n",
    "        return numerator / denominator\n",
    "    \n",
    "# PearsonRecommend function\n",
    "def PearsonRecommend(nouveauCritique, critiques, movies_to_consider):\n",
    "    totals = {}\n",
    "    sim_sums = {}\n",
    "    for movie in movies_to_consider:\n",
    "        totals[movie] = 0.0\n",
    "        sim_sums[movie] = 0.0\n",
    "\n",
    "    for critic in critiques:\n",
    "        if critic == nouveauCritique:\n",
    "            continue\n",
    "        similarity = pearson(critiques[critic], critiques[nouveauCritique])\n",
    "        if similarity == 0:\n",
    "            continue  # No similarity\n",
    "        for movie in movies_to_consider:\n",
    "            if movie in critiques[critic] and not pd.isna(critiques[critic][movie]):\n",
    "                if movie not in critiques[nouveauCritique] or pd.isna(critiques[nouveauCritique][movie]):\n",
    "                    totals[movie] += critiques[critic][movie] * similarity\n",
    "                    sim_sums[movie] += similarity\n",
    "\n",
    "    rankings = []\n",
    "    for movie in movies_to_consider:\n",
    "        if sim_sums[movie] != 0:\n",
    "            score = totals[movie] / sim_sums[movie]\n",
    "            rankings.append((score, movie))\n",
    "    rankings.sort(reverse=True)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ede46b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recommendations for Anne using Pearson correlation coefficient:\n",
      "Movie: Superman, Predicted Rating: 4.18\n",
      "Movie: Night, Predicted Rating: 4.06\n",
      "Movie: Snakes, Predicted Rating: 3.62\n"
     ]
    }
   ],
   "source": [
    "# Movies to consider\n",
    "movies_to_consider = ['Snakes', 'Superman', 'Night']\n",
    "\n",
    "# Testing PearsonRecommend\n",
    "print(\"Best recommendations for Anne using Pearson correlation coefficient:\")\n",
    "pearson_recommendations = PearsonRecommend('Anne', critiques, movies_to_consider)\n",
    "for score, movie in pearson_recommendations:\n",
    "    print(f\"Movie: {movie}, Predicted Rating: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaab17",
   "metadata": {},
   "source": [
    "## Question 2(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a63fbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(person1, person2):\n",
    "    sum_xy = 0\n",
    "    sum_x2 = 0\n",
    "    sum_y2 = 0\n",
    "    for key in person1:\n",
    "        if key in person2:\n",
    "            x = person1[key]\n",
    "            y = person2[key]\n",
    "            if not pd.isna(x) and not pd.isna(y):\n",
    "                sum_xy += x * y\n",
    "                sum_x2 += x ** 2\n",
    "                sum_y2 += y ** 2\n",
    "    if sum_x2 == 0 or sum_y2 == 0:\n",
    "        return 0 \n",
    "    return sum_xy / (sqrt(sum_x2) * sqrt(sum_y2))\n",
    "\n",
    "def CosineRecommend(nouveauCritique, critiques, movies_to_consider):\n",
    "    totals = {}\n",
    "    sim_sums = {}\n",
    "    for movie in movies_to_consider:\n",
    "        totals[movie] = 0.0\n",
    "        sim_sums[movie] = 0.0\n",
    "\n",
    "    for critic in critiques:\n",
    "        if critic == nouveauCritique:\n",
    "            continue\n",
    "        similarity = cosine_similarity(critiques[critic], critiques[nouveauCritique])\n",
    "        if similarity <= 0:\n",
    "            continue \n",
    "        for movie in movies_to_consider:\n",
    "            if movie in critiques[critic] and not pd.isna(critiques[critic][movie]):\n",
    "                if movie not in critiques[nouveauCritique] or pd.isna(critiques[nouveauCritique][movie]):\n",
    "                    totals[movie] += critiques[critic][movie] * similarity\n",
    "                    sim_sums[movie] += similarity\n",
    "\n",
    "    rankings = []\n",
    "    for movie in movies_to_consider:\n",
    "        if sim_sums[movie] != 0:\n",
    "            score = totals[movie] / sim_sums[movie]\n",
    "            rankings.append((round(score, 2), movie)) \n",
    "    rankings.sort(reverse=True)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3af58901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recommendations for Anne using Cosine similarity:\n",
      "Movie: Superman, Predicted Rating: 3.99\n",
      "Movie: Snakes, Predicted Rating: 3.72\n",
      "Movie: Night, Predicted Rating: 3.44\n"
     ]
    }
   ],
   "source": [
    "movies_to_consider = ['Snakes', 'Superman', 'Night']\n",
    "\n",
    "print(\"Best recommendations for Anne using Cosine similarity:\")\n",
    "cosine_recommendations = CosineRecommend('Anne', critiques, movies_to_consider)\n",
    "for score, movie in cosine_recommendations:\n",
    "    print(f\"Movie: {movie}, Predicted Rating: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52242d7b",
   "metadata": {},
   "source": [
    "## Question 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "969b650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Critic': ['Angelica', 'Bill', 'Chan', 'Dan', 'Hailey', 'Jordyn', 'Sam', 'Veronica'],\n",
    "    'Blues Traveler': [3.5, 2, 5, 3, None, None, 5, 3],\n",
    "    'Broken Bells': [2, 3.5, 1, 4, 4, 4.5, 2, None],\n",
    "    'Deadmau5': [None, 4, 1, 4.5, 1, 4, None, None],\n",
    "    'Norah Jones': [4.5, None, 3, None, 4, 5, 3, 5],\n",
    "    'Phoenix': [5, 2, 5, 3, None, 5, 5, 4],\n",
    "    'Slightly Stoopid': [1.5, 3.5, 1, 4.5, None, 4.5, 4, 2.5],\n",
    "    'The Strokes': [2.5, None, None, 4, 4, 4, 5, 3],\n",
    "    'Vampire Weekend': [2, 3, None, 2, 1, 4, None, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('Critic', inplace=True)\n",
    "\n",
    "critiques = df.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be6d294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Veronica:\n",
      "\n",
      "Using Manhattan similarity:\n",
      " - Broken Bells: Predicted Rating 3.24\n",
      " - Deadmau5: Predicted Rating 2.78\n",
      " - Vampire Weekend: Predicted Rating 2.23\n",
      "\n",
      "Using Euclidean similarity:\n",
      " - Broken Bells: Predicted Rating 3.12\n",
      " - Deadmau5: Predicted Rating 2.82\n",
      " - Vampire Weekend: Predicted Rating 2.27\n",
      "\n",
      "Using Pearson similarity:\n",
      " - Deadmau5: Predicted Rating 3.68\n",
      " - Broken Bells: Predicted Rating 3.27\n",
      " - Vampire Weekend: Predicted Rating 2.41\n",
      "\n",
      "Using Cosine similarity:\n",
      " - Broken Bells: Predicted Rating 3.02\n",
      " - Deadmau5: Predicted Rating 2.91\n",
      " - Vampire Weekend: Predicted Rating 2.4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Recommendations for Hailey:\n",
      "\n",
      "Using Manhattan similarity:\n",
      " - Phoenix: Predicted Rating 4.14\n",
      " - Blues Traveler: Predicted Rating 3.59\n",
      " - Slightly Stoopid: Predicted Rating 2.93\n",
      "\n",
      "Using Euclidean similarity:\n",
      " - Phoenix: Predicted Rating 4.18\n",
      " - Blues Traveler: Predicted Rating 3.6\n",
      " - Slightly Stoopid: Predicted Rating 2.95\n",
      "\n",
      "Using Pearson similarity:\n",
      " - Phoenix: Predicted Rating 4.05\n",
      " - Blues Traveler: Predicted Rating 3.53\n",
      " - Slightly Stoopid: Predicted Rating 3.11\n",
      "\n",
      "Using Cosine similarity:\n",
      " - Phoenix: Predicted Rating 4.18\n",
      " - Blues Traveler: Predicted Rating 3.61\n",
      " - Slightly Stoopid: Predicted Rating 3.06\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Songs to consider\n",
    "songs_to_consider = ['Blues Traveler', 'Broken Bells', 'Deadmau5', 'Norah Jones', 'Phoenix', 'Slightly Stoopid', 'The Strokes', 'Vampire Weekend']\n",
    "# Test results for Veronica and Hailey\n",
    "results = {\n",
    "    'Veronica': {\n",
    "        'Manhattan': Bestrecommend('Veronica', critiques, songs_to_consider, sim_distanceManhattan),\n",
    "        'Euclidean': Bestrecommend('Veronica', critiques, songs_to_consider, sim_distanceEuclidienne),\n",
    "        'Pearson': Bestrecommend('Veronica', critiques, songs_to_consider, pearson),\n",
    "        'Cosine': CosineRecommend('Veronica', critiques, songs_to_consider)\n",
    "    },\n",
    "    'Hailey': {\n",
    "        'Manhattan': Bestrecommend('Hailey', critiques, songs_to_consider, sim_distanceManhattan),\n",
    "        'Euclidean': Bestrecommend('Hailey', critiques, songs_to_consider, sim_distanceEuclidienne),\n",
    "        'Pearson': Bestrecommend('Hailey', critiques, songs_to_consider, pearson),\n",
    "        'Cosine': CosineRecommend('Hailey', critiques, songs_to_consider)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print results with explanations\n",
    "for person, recommendations in results.items():\n",
    "    print(f\"Recommendations for {person}:\\n\")\n",
    "    for method, recs in recommendations.items():\n",
    "        print(f\"Using {method} similarity:\")\n",
    "        for score, song in recs:\n",
    "            print(f\" - {song}: Predicted Rating {score}\")\n",
    "        print()\n",
    "    print(\"=\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4bfc21",
   "metadata": {},
   "source": [
    "## Question 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8cf183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_critics = 15\n",
    "num_movies = 20\n",
    "ratings = np.random.uniform(1, 5, size=(num_critics, num_movies))\n",
    "\n",
    "# Introduce missing values (30%-50% missing data)\n",
    "def apply_missing_data(matrix, missing_ratio=0.4):\n",
    "    total_cells = matrix.size\n",
    "    num_missing = int(total_cells * missing_ratio)\n",
    "    indices = [(i, j) for i in range(matrix.shape[0]) for j in range(matrix.shape[1])]\n",
    "    missing_indices = random.sample(indices, num_missing)\n",
    "    for i, j in missing_indices:\n",
    "        matrix[i, j] = np.nan\n",
    "    return matrix\n",
    "\n",
    "ratings = apply_missing_data(ratings.copy(), missing_ratio=0.4)\n",
    "\n",
    "critics = [f\"Critic_{i+1}\" for i in range(num_critics)]\n",
    "movies = [f\"Movie_{j+1}\" for j in range(num_movies)]\n",
    "ratings_df = pd.DataFrame(ratings, index=critics, columns=movies)\n",
    "\n",
    "# Ensure the target critic has not seen at least half of the movies\n",
    "ratings_df.iloc[0, :10] = np.nan  # Use .iloc for positional indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c20d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing data condition (30% - 50%) is satisfied.\n"
     ]
    }
   ],
   "source": [
    "def check_missing_data_proportion(df, min_percentage=0.3, max_percentage=0.5):\n",
    "    total_cells = df.size\n",
    "    missing_cells = df.isna().sum().sum()\n",
    "    missing_percentage = missing_cells / total_cells\n",
    "    return min_percentage <= missing_percentage <= max_percentage\n",
    "\n",
    "# Test the function\n",
    "if check_missing_data_proportion(ratings_df):\n",
    "    print(\"The missing data condition (30% - 50%) is satisfied.\")\n",
    "else:\n",
    "    print(\"The missing data condition is NOT satisfied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52abfbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chebyshev Distance\n",
    "def sim_chebyshev(person1, person2):\n",
    "    shared_movies = [\n",
    "        movie for movie in person1\n",
    "        if movie in person2 and not pd.isna(person1[movie]) and not pd.isna(person2[movie])\n",
    "    ]\n",
    "    if not shared_movies:\n",
    "        return float('inf')  # No ratings in common\n",
    "    ratings1 = np.array([person1[movie] for movie in shared_movies])\n",
    "    ratings2 = np.array([person2[movie] for movie in shared_movies])\n",
    "    distance = np.max(np.abs(ratings1 - ratings2))\n",
    "    return distance\n",
    "\n",
    "# Minkowski Distance (parameterized by p, e.g., p=3)\n",
    "def sim_minkowski(person1, person2, p=3):\n",
    "    shared_movies = [\n",
    "        movie for movie in person1\n",
    "        if movie in person2 and not pd.isna(person1[movie]) and not pd.isna(person2[movie])\n",
    "    ]\n",
    "    if not shared_movies:\n",
    "        return float('inf')  # No ratings in common\n",
    "    ratings1 = np.array([person1[movie] for movie in shared_movies])\n",
    "    ratings2 = np.array([person2[movie] for movie in shared_movies])\n",
    "    distance = np.sum(np.abs(ratings1 - ratings2) ** p) ** (1 / p)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfcf8e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations using Manhattan similarity:\n",
      "[(3.53, 'Movie_2'), (3.46, 'Movie_8'), (3.16, 'Movie_7'), (3.01, 'Movie_19'), (2.92, 'Movie_16'), (2.8, 'Movie_6'), (2.58, 'Movie_10'), (2.34, 'Movie_9')]\n",
      "\n",
      "Recommendations using Euclidean similarity:\n",
      "[(3.47, 'Movie_2'), (3.41, 'Movie_8'), (3.25, 'Movie_7'), (2.92, 'Movie_19'), (2.87, 'Movie_16'), (2.85, 'Movie_6'), (2.72, 'Movie_10'), (2.39, 'Movie_9')]\n",
      "\n",
      "Recommendations using Pearson similarity:\n",
      "[(3.56, 'Movie_8'), (3.28, 'Movie_7'), (3.05, 'Movie_9'), (2.95, 'Movie_10'), (2.94, 'Movie_2'), (2.92, 'Movie_6'), (2.58, 'Movie_19'), (2.44, 'Movie_16')]\n",
      "\n",
      "Recommendations using Cosine similarity:\n",
      "[(3.4, 'Movie_8'), (3.32, 'Movie_7'), (3.31, 'Movie_2'), (3.01, 'Movie_19'), (2.89, 'Movie_6'), (2.84, 'Movie_10'), (2.66, 'Movie_16'), (2.55, 'Movie_9')]\n",
      "\n",
      "Recommendations using Chebyshev similarity:\n",
      "[(3.43, 'Movie_8'), (3.42, 'Movie_2'), (3.26, 'Movie_7'), (2.89, 'Movie_6'), (2.86, 'Movie_19'), (2.85, 'Movie_16'), (2.81, 'Movie_10'), (2.49, 'Movie_9')]\n",
      "\n",
      "Recommendations using Minkowski similarity:\n",
      "[(3.45, 'Movie_2'), (3.41, 'Movie_8'), (3.27, 'Movie_7'), (2.89, 'Movie_19'), (2.87, 'Movie_6'), (2.85, 'Movie_16'), (2.76, 'Movie_10'), (2.42, 'Movie_9')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the target critic\n",
    "target_critic = 'Critic_2'\n",
    "\n",
    "# Define the list of movies to consider for recommendations (all movies in the DataFrame)\n",
    "movies_to_consider = ratings_df.columns.tolist()\n",
    "\n",
    "# Define similarity measures with the appropriate functions\n",
    "similarity_measures = {\n",
    "    \"Manhattan\": sim_distanceManhattan,\n",
    "    \"Euclidean\": sim_distanceEuclidienne,\n",
    "    \"Pearson\": pearson,\n",
    "    \"Cosine\": cosine_similarity,\n",
    "    \"Chebyshev\": sim_chebyshev,\n",
    "    \"Minkowski\": lambda p1, p2: sim_minkowski(p1, p2, p=3)\n",
    "}\n",
    "\n",
    "# Generate recommendations for each similarity measure\n",
    "recommendations = {}\n",
    "for name, func in similarity_measures.items():\n",
    "    recommendations[name] = Bestrecommend(target_critic, ratings_df.to_dict(orient=\"index\"), movies_to_consider, func)\n",
    "\n",
    "# Display results\n",
    "for name, recs in recommendations.items():\n",
    "    print(f\"Recommendations using {name} similarity:\")\n",
    "    print(recs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee08222",
   "metadata": {},
   "source": [
    "## Question 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "311b4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cityblock, euclidean, chebyshev, minkowski\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "196dcac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up parameters\n",
    "np.random.seed(42)\n",
    "num_critics = 50\n",
    "num_movies = 250\n",
    "missing_ratio = 0.4\n",
    "\n",
    "# Generate ratings with random values and allow NaN for missing data\n",
    "ratings = np.random.choice([1, 2, 3, 4, 5], size=(num_critics, num_movies)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1635f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply missing data\n",
    "def apply_missing_data(matrix, missing_ratio):\n",
    "    total_cells = matrix.size\n",
    "    num_missing = int(total_cells * missing_ratio)\n",
    "    indices = [(i, j) for i in range(matrix.shape[0]) for j in range(matrix.shape[1])]\n",
    "    missing_indices = random.sample(indices, num_missing)\n",
    "    for i, j in missing_indices:\n",
    "        matrix[i, j] = np.nan\n",
    "    return matrix\n",
    "\n",
    "ratings = apply_missing_data(ratings.copy(), missing_ratio)\n",
    "critics = [f\"Critic_{i+1}\" for i in range(num_critics)]\n",
    "movies = [f\"Movie_{j+1}\" for j in range(num_movies)]\n",
    "ratings_df = pd.DataFrame(ratings, index=critics, columns=movies)\n",
    "\n",
    "# Ensure target critic (Critic_1) has rated less than half the movies\n",
    "ratings_df.iloc[0, :int(num_movies / 2)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed90da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated similarity functions that handle missing data\n",
    "def pearson_similarity_safe(p1, p2):\n",
    "    mask = (~np.isnan(p1)) & (~np.isnan(p2))\n",
    "    if mask.sum() < 2:  # At least two ratings needed for Pearson\n",
    "        return 0\n",
    "    return pearsonr(p1[mask], p2[mask])[0]\n",
    "\n",
    "def cosine_similarity_safe(p1, p2):\n",
    "    mask = (~np.isnan(p1)) & (~np.isnan(p2))\n",
    "    if mask.sum() == 0:\n",
    "        return 0\n",
    "    return cosine_similarity([p1[mask]], [p2[mask]])[0][0]\n",
    "\n",
    "def manhattan_similarity(p1, p2):\n",
    "    mask = (~np.isnan(p1)) & (~np.isnan(p2))\n",
    "    return -cityblock(p1[mask], p2[mask]) if mask.sum() else 0\n",
    "\n",
    "def euclidean_similarity(p1, p2):\n",
    "    mask = (~np.isnan(p1)) & (~np.isnan(p2))\n",
    "    return -euclidean(p1[mask], p2[mask]) if mask.sum() else 0\n",
    "\n",
    "def chebyshev_similarity_safe(p1, p2):\n",
    "    mask = (~np.isnan(p1)) & (~np.isnan(p2))\n",
    "    return -chebyshev(p1[mask], p2[mask]) if mask.sum() else 0\n",
    "\n",
    "def minkowski_similarity_safe(p1, p2, p=3):\n",
    "    mask = (~np.isnan(p1)) & (~np.isnan(p2))\n",
    "    return -minkowski(p1[mask], p2[mask], p) if mask.sum() else 0\n",
    "\n",
    "# Assigning similarity measures to dictionary\n",
    "similarity_measures_safe = {\n",
    "    \"Pearson\": pearson_similarity_safe,\n",
    "    \"Cosine\": cosine_similarity_safe,\n",
    "    \"Manhattan\": manhattan_similarity,\n",
    "    \"Euclidean\": euclidean_similarity,\n",
    "    \"Chebyshev\": chebyshev_similarity_safe,\n",
    "    \"Minkowski\": lambda p1, p2: minkowski_similarity_safe(p1, p2, p=3)\n",
    "}\n",
    "\n",
    "# Placeholder for recommendations based on each similarity measure\n",
    "recommendations_safe = {}\n",
    "critiques = ratings_df.to_dict(orient=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aba0537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations using Pearson similarity:\n",
      "1. ('Critic_3', 0.30327308025146926)\n",
      "2. ('Critic_35', 0.29331900317538795)\n",
      "3. ('Critic_26', 0.22835899043463817)\n",
      "\n",
      "Recommendations using Cosine similarity:\n",
      "1. ('Critic_35', 0.8795989942670849)\n",
      "2. ('Critic_26', 0.8620508964742682)\n",
      "3. ('Critic_28', 0.861475859139698)\n",
      "\n",
      "Recommendations using Manhattan similarity:\n",
      "1. ('Critic_6', -49.0)\n",
      "2. ('Critic_36', -57.0)\n",
      "3. ('Critic_3', -58.0)\n",
      "\n",
      "Recommendations using Euclidean similarity:\n",
      "1. ('Critic_6', -10.535653752852738)\n",
      "2. ('Critic_24', -11.401754250991377)\n",
      "3. ('Critic_35', -11.532562594670797)\n",
      "\n",
      "Recommendations using Chebyshev similarity:\n",
      "1. ('Critic_22', -3.0)\n",
      "2. ('Critic_24', -3.0)\n",
      "3. ('Critic_35', -3.0)\n",
      "\n",
      "Recommendations using Minkowski similarity:\n",
      "1. ('Critic_24', -6.5731384514424285)\n",
      "2. ('Critic_6', -6.701759395378069)\n",
      "3. ('Critic_35', -6.760614301748689)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target critic for recommendations\n",
    "target_critic = 'Critic_1'\n",
    "movies_to_consider = ratings_df.columns.tolist()\n",
    "\n",
    "# Dummy function to simulate recommendation calculation\n",
    "def calculate_recommendations(target, critiques, movies, similarity_func):\n",
    "    scores = {}\n",
    "    for critic, ratings in critiques.items():\n",
    "        if critic != target:\n",
    "            p1 = np.array([ratings[movie] for movie in movies])\n",
    "            p2 = np.array([critiques[target][movie] for movie in movies])\n",
    "            score = similarity_func(p1, p2)\n",
    "            scores[critic] = score\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "# Calculate recommendations for each similarity measure\n",
    "for name, func in similarity_measures_safe.items():\n",
    "    recommendations_safe[name] = calculate_recommendations(target_critic, critiques, movies_to_consider, func)\n",
    "\n",
    "# Filter recommendations to find cases with completely different recommendations\n",
    "unique_recommendations = {}\n",
    "for name, recs in recommendations_safe.items():\n",
    "    unique_recommendations[name] = {rec[0] for rec in recs}  # Store only critic names for comparison\n",
    "\n",
    "# Check for complete difference in top recommendations\n",
    "if len(set.intersection(*unique_recommendations.values())) == 0:\n",
    "    # Print recommendations only if they are completely different\n",
    "    for name, recs in recommendations_safe.items():\n",
    "        print(f\"Recommendations using {name} similarity:\")\n",
    "        for i, recommendation in enumerate(recs, start=1):\n",
    "            print(f\"{i}. {recommendation}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No completely different recommendations across all six similarity measures.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
