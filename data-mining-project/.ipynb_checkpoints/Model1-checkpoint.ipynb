{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PVJCOh56S0z"
   },
   "source": [
    "Use file 'ar41_data.csv'.\n",
    "Put the notebook and data file in one folder.\n",
    "Run the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2730,
     "status": "ok",
     "timestamp": 1702553224961,
     "user": {
      "displayName": "Hareem Raza",
      "userId": "15812560497072251137"
     },
     "user_tz": -60
    },
    "id": "07woNvaCOHpQ"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import folium\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6270,
     "status": "ok",
     "timestamp": 1702553231225,
     "user": {
      "displayName": "Hareem Raza",
      "userId": "15812560497072251137"
     },
     "user_tz": -60
    },
    "id": "PfmCerXaCTnc",
    "outputId": "fd89d404-b22f-483a-b533-2345ae63a045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#drive.mount('/content/drive')\n",
    "#path = '/content/drive/My Drive/BDMA/Semester 1 - ULB/Personal Work/Data Mining Project/ar41_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2a35c2ea3a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ar41_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "dtypes = {\n",
    "    'mapped_veh_id': 'int32',\n",
    "    'RS_E_InAirTemp_PC1': 'float32',\n",
    "    'RS_E_InAirTemp_PC2': 'float32',\n",
    "    'RS_E_OilPress_PC1': 'float32',\n",
    "    'RS_E_OilPress_PC2': 'float32',\n",
    "    'RS_E_RPM_PC1': 'float32',\n",
    "    'RS_E_RPM_PC2': 'float32',\n",
    "    'RS_E_WatTemp_PC1': 'float32',\n",
    "    'RS_E_WatTemp_PC2': 'float32',\n",
    "    'RS_T_OilTemp_PC1': 'float32',\n",
    "    'RS_T_OilTemp_PC2': 'float32',\n",
    "    'temp':'float32',\n",
    "    'elevation':'float32'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('ar41_data.csv', delimiter=',', dtype=dtypes)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1702553319664,
     "user": {
      "displayName": "Hareem Raza",
      "userId": "15812560497072251137"
     },
     "user_tz": -60
    },
    "id": "ZQ5gTwqLEh9u"
   },
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0', 'timestamps_UTC', 'weather',\t'weather_description',\t'elevation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1SwRAnBCIY3",
    "outputId": "45786aa0-b0e8-4da7-ebb4-0e5c6cce3765"
   },
   "outputs": [],
   "source": [
    "def calculate_speed(df, lat_col='lat', lon_col='lon', time_diff_col='time_diff_overall', veh_id_col='mapped_veh_id', journey_id_col='journey_id'):\n",
    "    def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "        if to_radians:\n",
    "            lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "        a = np.sin((lat2 - lat1) / 2.0)**2 + \\\n",
    "            np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2.0)**2\n",
    "\n",
    "        return earth_radius * 2 * np.arcsin(np.sqrt(a))\n",
    "    # Calculate the speed of a train in km/h between successive rows, grouped by train and journey_id.\n",
    "    def calculate_group_speed(group):\n",
    "        # Calculate the distance for each group\n",
    "        group['distance'] = haversine(group[lat_col].shift(), group[lon_col].shift(), group[lat_col], group[lon_col])\n",
    "        # Calculate speed in km/h, avoid division by zero\n",
    "        group['speed'] = np.where(group[time_diff_col] > 0, (group['distance'] / group[time_diff_col]) * 3600, np.nan)\n",
    "        # Handle the first entry of each group\n",
    "        group['speed'].iloc[0] = 0\n",
    "        group['distance'].iloc[0] = 0\n",
    "        return group\n",
    "    # Group by vehicle id and journey id, then apply the speed calculation\n",
    "    df = df.groupby([veh_id_col], as_index=False).apply(calculate_group_speed)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def divide_journeys(data, time_threshold_1=300, time_threshold_2=600, speed_threshold = 0.5):\n",
    "    condition = (data['time_diff_overall'] >= time_threshold_1) & \\\n",
    "                (data['speed'] < speed_threshold) | \\\n",
    "                (data['time_diff_overall'] >= time_threshold_2)\n",
    "    data['time_diff'] = data['time_diff_overall'].where(~condition, 0).astype(int)\n",
    "    data['new_journey'] = (data['time_diff'] == 0).astype(int)\n",
    "    data['journey_id'] = data.groupby('mapped_veh_id')['new_journey'].cumsum()\n",
    "    data.drop('new_journey', axis=1, inplace=True)\n",
    "\n",
    "data = calculate_speed(data)\n",
    "divide_journeys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('journeys.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ed7e8fa9663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'journeys.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m    539\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('journeys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_veh_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>RS_E_InAirTemp_PC1</th>\n",
       "      <th>RS_E_InAirTemp_PC2</th>\n",
       "      <th>RS_E_OilPress_PC1</th>\n",
       "      <th>RS_E_OilPress_PC2</th>\n",
       "      <th>RS_E_RPM_PC1</th>\n",
       "      <th>RS_E_RPM_PC2</th>\n",
       "      <th>RS_E_WatTemp_PC1</th>\n",
       "      <th>...</th>\n",
       "      <th>RS_T_OilTemp_PC1</th>\n",
       "      <th>RS_T_OilTemp_PC2</th>\n",
       "      <th>temp</th>\n",
       "      <th>timestamps_Belgian</th>\n",
       "      <th>time_diff_overall</th>\n",
       "      <th>distance</th>\n",
       "      <th>speed</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>journey_id</th>\n",
       "      <th>rolling_avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16933287</th>\n",
       "      <td>194</td>\n",
       "      <td>51.041244</td>\n",
       "      <td>3.683576</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2023-01-23 09:28:12+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933288</th>\n",
       "      <td>194</td>\n",
       "      <td>51.041278</td>\n",
       "      <td>3.683609</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2023-01-23 09:29:14+00:00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933289</th>\n",
       "      <td>194</td>\n",
       "      <td>51.041239</td>\n",
       "      <td>3.683588</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2023-01-23 09:30:15+00:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.266795</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933290</th>\n",
       "      <td>194</td>\n",
       "      <td>51.041247</td>\n",
       "      <td>3.683568</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2023-01-23 09:31:15+00:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.101943</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933291</th>\n",
       "      <td>194</td>\n",
       "      <td>51.041239</td>\n",
       "      <td>3.683581</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2023-01-23 09:32:15+00:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.078296</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141764</th>\n",
       "      <td>194</td>\n",
       "      <td>51.013760</td>\n",
       "      <td>3.779578</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.09</td>\n",
       "      <td>2023-09-13 19:39:19+00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.150633</td>\n",
       "      <td>50</td>\n",
       "      <td>432</td>\n",
       "      <td>0.651861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141765</th>\n",
       "      <td>194</td>\n",
       "      <td>51.013759</td>\n",
       "      <td>3.779588</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.09</td>\n",
       "      <td>2023-09-13 19:39:30+00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.250217</td>\n",
       "      <td>11</td>\n",
       "      <td>432</td>\n",
       "      <td>0.200425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141766</th>\n",
       "      <td>194</td>\n",
       "      <td>51.013762</td>\n",
       "      <td>3.779574</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.09</td>\n",
       "      <td>2023-09-13 19:40:29+00:00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.065017</td>\n",
       "      <td>59</td>\n",
       "      <td>432</td>\n",
       "      <td>0.157617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141767</th>\n",
       "      <td>194</td>\n",
       "      <td>51.013464</td>\n",
       "      <td>3.780101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.09</td>\n",
       "      <td>2023-09-13 19:41:30+00:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>2.926191</td>\n",
       "      <td>61</td>\n",
       "      <td>432</td>\n",
       "      <td>1.495604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141768</th>\n",
       "      <td>194</td>\n",
       "      <td>51.013511</td>\n",
       "      <td>3.780150</td>\n",
       "      <td>43.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.09</td>\n",
       "      <td>2023-09-13 19:42:30+00:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.374416</td>\n",
       "      <td>60</td>\n",
       "      <td>432</td>\n",
       "      <td>1.650304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208482 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mapped_veh_id        lat       lon  RS_E_InAirTemp_PC1  \\\n",
       "16933287            194  51.041244  3.683576                17.0   \n",
       "16933288            194  51.041278  3.683609                17.0   \n",
       "16933289            194  51.041239  3.683588                17.0   \n",
       "16933290            194  51.041247  3.683568                17.0   \n",
       "16933291            194  51.041239  3.683581                17.0   \n",
       "...                 ...        ...       ...                 ...   \n",
       "17141764            194  51.013760  3.779578                32.0   \n",
       "17141765            194  51.013759  3.779588                32.0   \n",
       "17141766            194  51.013762  3.779574                32.0   \n",
       "17141767            194  51.013464  3.780101                 0.0   \n",
       "17141768            194  51.013511  3.780150                43.0   \n",
       "\n",
       "          RS_E_InAirTemp_PC2  RS_E_OilPress_PC1  RS_E_OilPress_PC2  \\\n",
       "16933287                28.0              207.0              238.0   \n",
       "16933288                28.0              213.0              244.0   \n",
       "16933289                28.0              210.0              231.0   \n",
       "16933290                28.0              217.0              238.0   \n",
       "16933291                28.0              213.0              244.0   \n",
       "...                      ...                ...                ...   \n",
       "17141764                38.0              203.0              227.0   \n",
       "17141765                38.0              207.0              227.0   \n",
       "17141766                38.0              200.0              227.0   \n",
       "17141767                 0.0                0.0                0.0   \n",
       "17141768                48.0                0.0                3.0   \n",
       "\n",
       "          RS_E_RPM_PC1  RS_E_RPM_PC2  RS_E_WatTemp_PC1  ...  RS_T_OilTemp_PC1  \\\n",
       "16933287           0.0         808.0              77.0  ...              73.0   \n",
       "16933288           0.0         816.0              77.0  ...              71.0   \n",
       "16933289           0.0         801.0              77.0  ...              72.0   \n",
       "16933290           0.0         791.0              77.0  ...              73.0   \n",
       "16933291           0.0         796.0              77.0  ...              71.0   \n",
       "...                ...           ...               ...  ...               ...   \n",
       "17141764         802.0         798.0              82.0  ...              76.0   \n",
       "17141765         802.0         804.0              82.0  ...              76.0   \n",
       "17141766         796.0         799.0              82.0  ...              76.0   \n",
       "17141767           0.0           0.0               0.0  ...              77.0   \n",
       "17141768           0.0           0.0              82.0  ...              76.0   \n",
       "\n",
       "          RS_T_OilTemp_PC2   temp         timestamps_Belgian  \\\n",
       "16933287              76.0   1.56  2023-01-23 09:28:12+00:00   \n",
       "16933288              76.0   1.56  2023-01-23 09:29:14+00:00   \n",
       "16933289              76.0   1.56  2023-01-23 09:30:15+00:00   \n",
       "16933290              76.0   1.56  2023-01-23 09:31:15+00:00   \n",
       "16933291              77.0   1.56  2023-01-23 09:32:15+00:00   \n",
       "...                    ...    ...                        ...   \n",
       "17141764              81.0  19.09  2023-09-13 19:39:19+00:00   \n",
       "17141765              81.0  19.09  2023-09-13 19:39:30+00:00   \n",
       "17141766              82.0  19.09  2023-09-13 19:40:29+00:00   \n",
       "17141767              82.0  19.09  2023-09-13 19:41:30+00:00   \n",
       "17141768              81.0  19.09  2023-09-13 19:42:30+00:00   \n",
       "\n",
       "         time_diff_overall  distance     speed  time_diff  journey_id  \\\n",
       "16933287               0.0  0.000000  0.000000          0           1   \n",
       "16933288              62.0  0.004398  0.255396         62           1   \n",
       "16933289              61.0  0.004521  0.266795         61           1   \n",
       "16933290              60.0  0.001699  0.101943         60           1   \n",
       "16933291              60.0  0.001305  0.078296         60           1   \n",
       "...                    ...       ...       ...        ...         ...   \n",
       "17141764              50.0  0.002092  0.150633         50         432   \n",
       "17141765              11.0  0.000765  0.250217         11         432   \n",
       "17141766              59.0  0.001066  0.065017         59         432   \n",
       "17141767              61.0  0.049583  2.926191         61         432   \n",
       "17141768              60.0  0.006240  0.374416         60         432   \n",
       "\n",
       "          rolling_avg_speed  \n",
       "16933287           0.127698  \n",
       "16933288           0.127698  \n",
       "16933289           0.261095  \n",
       "16933290           0.184369  \n",
       "16933291           0.090120  \n",
       "...                     ...  \n",
       "17141764           0.651861  \n",
       "17141765           0.200425  \n",
       "17141766           0.157617  \n",
       "17141767           1.495604  \n",
       "17141768           1.650304  \n",
       "\n",
       "[208482 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[data['mapped_veh_id'] == 162]\n",
    "data[data['mapped_veh_id'] == 194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('train162.csv', index=False)\n",
    "\n",
    "# data[data['mapped_veh_id'] == 162].to_csv('train162.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('train162.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['mapped_veh_id'] == 194].to_excel('train194.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29ce668332d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mapped_veh_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m162\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train162.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# data[data['mapped_veh_id'] == 194].to_csv('train194.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fTH_qU0RCIY5"
   },
   "outputs": [],
   "source": [
    "columns_to_check = ['RS_E_InAirTemp_PC2', 'RS_E_OilPress_PC2', 'RS_E_RPM_PC2', 'RS_E_WatTemp_PC2', 'RS_T_OilTemp_PC2']\n",
    "data.dropna(subset=columns_to_check, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T3C1Vm24CIY6"
   },
   "outputs": [],
   "source": [
    "def rolling_operation(x):\n",
    "    return x.rolling(window=2).mean().bfill().ffill()\n",
    "data['rolling_avg_speed'] = data.groupby(['mapped_veh_id', 'journey_id'])['speed'].transform(rolling_operation)\n",
    "data['rolling_avg_speed'] = data['rolling_avg_speed'].fillna(data['speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb82BbeMCIY7",
    "outputId": "b4b6b59d-6b9b-493a-84fe-e9eaa6229c36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hareem Raza\\AppData\\Local\\Temp\\ipykernel_10320\\1559081916.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  check['anomaly'] = model.predict(features_normalized)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anomaly\n",
       " 1    7579\n",
       "-1    2421\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "check = data.head(100000)\n",
    "# Assuming 'data' is your DataFrame and includes all the necessary columns\n",
    "# Preprocessing: Select relevant features and normalize\n",
    "features = check[['RS_E_InAirTemp_PC1', 'RS_E_OilPress_PC1', 'RS_E_RPM_PC1', 'RS_E_WatTemp_PC1', 'RS_T_OilTemp_PC1', 'RS_E_InAirTemp_PC2', 'RS_E_OilPress_PC2', 'RS_E_RPM_PC2', 'RS_E_WatTemp_PC2', 'RS_T_OilTemp_PC2', 'rolling_avg_speed']]\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)\n",
    "\n",
    "# Instantiate and fit the Isolation Forest model\n",
    "model = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=42)\n",
    "model.fit(features_normalized)\n",
    "\n",
    "# Predict anomalies\n",
    "check['anomaly'] = model.predict(features_normalized)\n",
    "check['anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM-aZrLGCIY7",
    "outputId": "6da369ef-80af-47f2-d258-1f8722aa14e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_dbscan\n",
      "0    6226\n",
      "1    3774\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hareem Raza\\AppData\\Local\\Temp\\ipykernel_10320\\1958940382.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  check['anomaly_dbscan'] = (clusters == -1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'check' is a subset of the data\n",
    "# Preprocessing: Select relevant features and normalize\n",
    "features =  check[['RS_E_InAirTemp_PC1', 'RS_E_OilPress_PC1', 'RS_E_RPM_PC1', 'RS_E_WatTemp_PC1', 'RS_T_OilTemp_PC1', 'RS_E_InAirTemp_PC2', 'RS_E_OilPress_PC2', 'RS_E_RPM_PC2', 'RS_E_WatTemp_PC2', 'RS_T_OilTemp_PC2', 'rolling_avg_speed']]\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)\n",
    "\n",
    "# Instantiate and fit the DBSCAN model\n",
    "# Note: You need to choose appropriate values for eps and min_samples\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=10)\n",
    "clusters = dbscan.fit_predict(features_normalized)\n",
    "\n",
    "# Mark anomalies (DBSCAN labels outliers as -1)\n",
    "check['anomaly_dbscan'] = (clusters == -1).astype(int)\n",
    "# Review the results\n",
    "print(check['anomaly_dbscan'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4zKPdIACIY8"
   },
   "outputs": [],
   "source": [
    "# Set the timestamp as the index\n",
    "check.set_index('timestamps_Belgian', inplace=True)\n",
    "# Sort the data by the index (timestamp)\n",
    "check.sort_index(inplace=True)\n",
    "# Select the feature for ARIMA modeling, e.g., 'speed'\n",
    "time_series = check[['RS_E_InAirTemp_PC1', 'RS_E_OilPress_PC1', 'RS_E_RPM_PC1', 'RS_E_WatTemp_PC1', 'RS_T_OilTemp_PC1', 'rolling_avg_speed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhPoQatbCIY9"
   },
   "source": [
    "## VARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KP2GDGAFCIY9"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features =  check[['RS_E_InAirTemp_PC1', 'RS_E_OilPress_PC1', 'RS_E_RPM_PC1', 'RS_E_WatTemp_PC1', 'RS_T_OilTemp_PC1', 'RS_E_InAirTemp_PC2', 'RS_E_OilPress_PC2', 'RS_E_RPM_PC2', 'RS_E_WatTemp_PC2', 'RS_T_OilTemp_PC2', 'rolling_avg_speed']]\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXYZEyq7CIY9",
    "outputId": "cbb945c8-d65a-4443-ad0c-9aa6c25eb5fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\statsmodels\\tsa\\statespace\\varmax.py:161: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
      "  warn('Estimation of VARMA(p,q) models is not generically robust,'\n",
      "C:\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Python310\\lib\\site-packages\\statsmodels\\tsa\\statespace\\varmax.py:326: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  endog = np.require(endog.fillna(method='backfill'), requirements=\"W\")\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import VARMAX\n",
    "# Convert normalized features to DataFrame\n",
    "features_df = pd.DataFrame(features_normalized, columns=features.columns, index=check.index)\n",
    "# Fit VARIMA model\n",
    "# Note: Determine the order (p, d, q) appropriately; here, we use (1,1,1) as an example\n",
    "model = VARMAX(features_df, order=(1, 1), trend='c').fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1Ru8hsQCIY-"
   },
   "outputs": [],
   "source": [
    "# Get residuals\n",
    "residuals = model.resid\n",
    "\n",
    "# Anomaly detection - mark as anomaly if residuals for any variable are beyond a threshold\n",
    "anomaly_threshold = 2.5  # Define based on your understanding of the data\n",
    "check['anomaly'] = residuals.apply(lambda x: np.any(np.abs(x) > anomaly_threshold), axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etxtKef8CIY-"
   },
   "outputs": [],
   "source": [
    "# Check anomaly counts\n",
    "print(check['anomaly'].value_counts())\n",
    "# Optionally, inspect some of the anomalies\n",
    "print(check[check['anomaly'] == 1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
