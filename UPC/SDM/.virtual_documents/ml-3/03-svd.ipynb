


# Uncomment to upgrade packages
#!pip3 install pandas --user --upgrade --quiet
#!pip3 install scipy --user --upgrade --quiet
#!pip3 install numpy --user --upgrade --quiet
#!pip3 install statsmodels --user --upgrade --quiet
#!pip3 install seaborn --user --upgrade --quiet
#!pip3 install pillow --user --upgrade -- quiet
#!pip3 install matplotlib --user --upgrade --quiet


%load_ext autoreload


import numpy as np
import pandas as pd

pd.set_option('display.precision', 3)
np.set_printoptions(precision=3)














from numpy.linalg import eig, inv

# generate random symmetric matrix
n=5
a = np.random.randint(50, size=(n, n))
A = np.tril(a) + np.tril(a, -1).T
print(A)


eigvalues, eigvectors = eig(A)

print(f'Eigenvalues: {eigvalues}')
print(f'Eigenvectors:')
print(eigvectors)


print(A @ eigvectors)
print()
print(eigvectors @ np.diag(eigvalues))





# make sure they are the same..
print(f'AQ =? QL: {np.allclose(A @ eigvectors, eigvectors @ np.diag(eigvalues))}')











murders = pd.read_csv('murders.txt', sep=' ')
murders['offset'] = [1.0] * len(murders)
murders.head()


X = murders[['offset', 'inhabitants', 'income', 'unemployment']].to_numpy()
print(X.shape)
y = murders[['murders']].to_numpy()
print(y.shape)


from numpy.linalg import svd, pinv, inv


# compute theta the direct way
theta_inv = inv(X.T @ X) @ X.T @ y
theta_inv


# compute theta the pseudoinverse way
from numpy.linalg import pinv

theta_pinv = pinv(X) @ y
theta_pinv


# compute theta the SVD way

U,d,Vt = svd(X, full_matrices=False)
theta_svd = Vt.T @ np.diag(1/d) @ U.T @ y
theta_svd


# check they are the same..
np.allclose(theta_inv, theta_svd)








from PIL import Image
import matplotlib.pyplot as plt

image = Image.open('cat.jpg')
A = np.array(image)
plt.imshow(image)
plt.axis('off')
plt.show()
A.shape


#convert to 2D image from 3 RGB channels

X = np.mean(A, axis=2)
plt.imshow(X, cmap=plt.cm.gray)
plt.axis('off')
print(X.shape)
print(f'original image uses {np.prod(X.shape)} values')





U,d,Vt = svd(X)
D = np.diag(d)

np.allclose(X, U @ D @ Vt)


# k looping through sequence of powers of 2
m,n = X.shape
nm = np.prod(X.shape)
print(f'Original image needs {n} x {m} = {nm} values')
j = 0
plt.figure(figsize=(18, 8))
for k in [1 << i for i in range(9)]:
    plt.subplot(2,5,j+1)
    j += 1
    ## construct approximation of X with first $k$ dimensions
    X_approx = U[:,:k] @ D[:k,:k] @ Vt[:k,:]
    plt.imshow(X_approx, cmap=plt.cm.gray)
    plt.axis('off')
    storage = k*(m+n+1)
    plt.title(f'k = {k}; {storage} values; {storage/nm*100:.1f}%')





plt.figure(figsize=(16,4))
plt.subplot(131)
plt.plot(d)
plt.title('Singular values')

plt.subplot(132)
plt.semilogy(d)
plt.title('Singular values in log scale')

plt.subplot(133)
plt.plot(np.cumsum(d) / np.sum(d))
plt.title('Cumulative sum of singular values')








from sklearn.datasets import fetch_lfw_people
faces = fetch_lfw_people(min_faces_per_person=17)   # only load images of people for which we have >= 17 images

n = faces.data.shape[0]


print(faces.target_names[:20])

print(f'faces.data.shape: {faces.data.shape}')
print(f'faces.image.shape: {faces.images.shape}')



# size of first image, we assume all images are the same size..
h, w = faces.images[0].shape

print(f'Found {n} images of size {h} x {w} = {h*w} belonging to {len(faces.target_names)} different persons.')

X = faces.data    # X is a matrix of shape 4324 x 2914 containing flattened images in each row

assert X.shape[1] == h * w

print(f'data matrix X has size {X.shape} -- one flattened image in each row')





plt.figure(figsize=(20, 20))

# select 100 random images
rand_images = np.random.randint(n, size=100)

for i in range(10*10):
    plt.subplot(10,10,i+1)
    idx = rand_images[i]  # pick random person (random row from X)
    plt.imshow(X[idx,:].reshape(h,w), cmap=plt.cm.gray)
    plt.axis('off')
    plt.title(faces.target_names[faces.target[idx]])






mean_face = X.mean(axis=0)
plt.imshow(np.reshape(mean_face, (h,w)), cmap=plt.cm.gray)
plt.title("Mean Face")
plt.axis('off')
plt.show()


# center data
cX = X - mean_face





plt.figure(figsize=(20, 20))
for i in range(10*10):
    plt.subplot(10,10,i+1)
    idx = rand_images[i]  # pick random person (random row from X)
    plt.imshow(cX[idx,:].reshape(h,w), cmap=plt.cm.gray)
    plt.axis('off')
    plt.title(faces.target_names[faces.target[idx]])



%%time
U, d, Vt = svd(cX, full_matrices=False)


U.shape, d.shape, Vt.shape


# check it worked..

svd_X = U @ np.diag(d) @ Vt

print(np.allclose(cX, svd_X, atol=1e-08))
print(np.allclose(cX, svd_X, atol=1e-03))

from scipy import stats

stats.describe(cX - svd_X, axis=None)





plt.figure(figsize=(10, 10))
for i in range(10*10):
    plt.subplot(10,10,i+1)
    plt.imshow(Vt[i,:].reshape(h,w), cmap=plt.cm.gray)
    plt.axis('off')    





plt.figure(figsize=(12,4))
plt.subplot(131)
plt.plot(d)
plt.title('Singular values')

plt.subplot(132)
plt.semilogy(d)
plt.title('Singular values in log scale')

plt.subplot(133)
plt.plot(np.cumsum(d) / np.sum(d))
plt.title('Cumulative sum of singular values')








i = np.random.randint(n) # select random image
alpha = U[i,:] @ np.diag(d)
print(alpha.shape)
print(alpha)


plt.imshow((mean_face + cX[i,:]).reshape(h,w), cmap=plt.cm.gray)
plt.axis('off');





plt.figure(figsize=(15, 40))
j = 1
k_range = [5, 50, 100, 300, 1000, 2000, Vt.shape[0]] 
for k in k_range:
    plt.subplot(1,len(k_range),j)
    j += 1
    reconstructed = mean_face + alpha[:k] @ Vt[:k,:]
    plt.imshow(reconstructed.reshape(h,w), cmap=plt.cm.gray)
    plt.axis('off')
    plt.title('k = ' + str(k))





# pick an image outside X

image = Image.open('Aaron_Eckhart_0001.jpg')
image = image.crop((60, 25, 185, 200))
image = image.resize((w, h))
plt.imshow(image)

A = np.array(image).mean(axis=2)

new_x = A.reshape(1 , -1) - mean_face
new_alpha = new_x @ Vt.T
new_alpha = new_alpha.reshape(-1)



plt.figure(figsize=(15, 40))
j = 1
k_range = [5, 50, 100, 300, 1000, 2000, Vt.shape[0]] 
for k in k_range:
    plt.subplot(1,len(k_range),j)
    j += 1
    reconstructed = mean_face + new_alpha[:k] @ Vt[:k,:]
    plt.imshow(reconstructed.reshape(h,w), cmap=plt.cm.gray)
    plt.title('k = ' + str(k))
    plt.axis('off')





# find images from a name
watts_pos = np.where(faces.target_names =='Naomi Watts')[0][0]
gates_pos = np.where(faces.target_names =='Bill Gates')[0][0]

#print(watts_pos, gates_pos)

watts_idx = np.where(faces.target == watts_pos)[0]
gates_idx = np.where(faces.target == gates_pos)[0]

#print(f'Naomi in rows: {watts_idx}')
#print(f'Gates in rows: {gates_idx}')

print(f'Found {len(watts_idx)} images of Naomi Watts; {len(gates_idx)} images from Bill Gates')


# show random images from both persons
import random

def show_pics(flist, k):
    plt.figure(figsize=(15, 40))
    for i, idx in enumerate(random.sample(list(flist), k)):
        plt.subplot(1, k, i+1)
        plt.imshow(faces.images[idx,:,:], cmap=plt.cm.gray)
        plt.axis('off')
        
show_pics(watts_idx, 5)
show_pics(gates_idx, 5)


# get coordinates for both using 2 eigenfaces
eigen_modes = [4, 10]
def get_coord(flist):
    res = np.zeros((len(flist), 2))
    for i, idx in enumerate(list(flist)):
        x = faces.images[idx,:,:].reshape(1 , -1) - mean_face
        alpha = (x @ Vt.T).reshape(-1)
        res[i,:] = alpha[eigen_modes]
    return res
naomi = get_coord(watts_idx)
bill = get_coord(gates_idx)


# plot them in 2D
plt.plot(naomi[:,0], naomi[:,1], '.', color='m', label='Naomi Watts')
plt.plot(bill[:,0], bill[:,1], 'x', color='b', label='Bill Gates')
plt.axis('off')
plt.legend()



