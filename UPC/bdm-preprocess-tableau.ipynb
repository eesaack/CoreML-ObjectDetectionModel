{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af33727e-2639-4761-81da-42d0c1cea16d",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Visualization in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd7d026-e664-478d-bf53-66c2059b470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810da7c-5dd3-408d-ba20-5896a78ee009",
   "metadata": {},
   "source": [
    "Meetup Data from Json to Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e90b475-6dde-4383-baac-089fca49d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meetup-20240407.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('event.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    if '_id' in item and '$oid' in item['_id']:\n",
    "        item['_id'] = item['_id']['$oid']\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c86378-f125-4517-9c6e-3484994828c2",
   "metadata": {},
   "source": [
    "Posts from Json to Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645cfa3e-42e9-4e9c-bbd7-c4e1eb460758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('post-20240407.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('post.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9f8d1-47c2-49a9-a7b6-c4afb3ebed95",
   "metadata": {},
   "source": [
    "second post data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26653c7e-1846-49a8-9e6a-a4f3251d32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('system_data.postd_ata.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('1post.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    if '_id' in item and '$oid' in item['_id']:\n",
    "        item['_id'] = item['_id']['$oid']\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42576e-1b47-4e99-95f9-74e885c97390",
   "metadata": {},
   "outputs": [],
   "source": [
    "user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a45d1ba-1c1d-47f5-8f27-eb42946eea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('system_data.user_info.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('user-data.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    if '_id' in item and '$oid' in item['_id']:\n",
    "        item['_id'] = item['_id']['$oid']\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1f2dd-512f-472a-97c4-b6cb934014de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c05a72-7a44-4bf0-b32c-a8ed0cf4270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4725a7b9-8030-4c38-98b2-ed9e9b081acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_json_string(raw_json):\n",
    "    \n",
    "    decoded_json = html.unescape(raw_json)\n",
    "    decoded_json = re.sub(r'\\\\u003c[a-zA-Z\\/][^>]*\\\\u003e', '', decoded_json)\n",
    "    decoded_json = decoded_json.replace('\\\\\"', '\"')\n",
    "    decoded_json = decoded_json.replace('\\\\n', '')\n",
    "    decoded_json = decoded_json.replace('\\\\\\\\', '\\\\')\n",
    "    decoded_json = re.sub(r'\\\\', '', decoded_json)\n",
    "    decoded_json = re.sub(r'(?<=\\})\\s*(?=\\{)', '},{', decoded_json)\n",
    "\n",
    "    last_brace_pos = decoded_json.rfind('}')\n",
    "    if last_brace_pos != -1:\n",
    "        decoded_json = decoded_json[:last_brace_pos + 1]\n",
    "\n",
    "    return '[' + decoded_json + ']'\n",
    "\n",
    "def extract_json_data(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        json_start_pos = content.find('{')\n",
    "        if json_start_pos == -1:\n",
    "            print(\"No JSON object found in the file.\")\n",
    "            return None\n",
    "        \n",
    "        json_content = content[json_start_pos:]\n",
    "        clean_content = clean_json_string(json_content)\n",
    "        return json.loads(clean_content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        error_position = e.pos\n",
    "        print(\"Error context (100 characters around error):\", clean_content[max(0, error_position-50):error_position+50])\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_json_to_csv(json_data, output_csv_path):\n",
    "    try:\n",
    "        df = pd.json_normalize(json_data)\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Data successfully saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting JSON to CSV: {e}\")\n",
    "\n",
    "json_data = extract_json_data('gym-data.txt')\n",
    "if json_data:\n",
    "    convert_json_to_csv(json_data, 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1dfea-79e3-44ae-ad35-6944b7f767ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "museum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c888c676-8011-4a95-908c-568e44c0432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON: Extra data: line 61 column 8 (char 2053)\n"
     ]
    }
   ],
   "source": [
    "def convert_json_to_csv(input_file_path, output_file_path):\n",
    "    # Open the input file and read the data\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    # Try to find the JSON object starting and ending points\n",
    "    start_index = data.find('{')\n",
    "    end_index = data.rfind('}') + 1  # Include the last curly brace\n",
    "    \n",
    "    # Extract the JSON substring\n",
    "    json_data = data[start_index:end_index]\n",
    "\n",
    "    # Attempt to parse the JSON data\n",
    "    try:\n",
    "        parsed_json = json.loads(json_data)\n",
    "        results = parsed_json.get('results', [])\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON:\", e)\n",
    "        return\n",
    "\n",
    "    # Define the fields to be included in the CSV\n",
    "    fields = [\n",
    "        'name', 'business_status', 'formatted_address', 'latitude', 'longitude',\n",
    "        'rating', 'user_ratings_total'\n",
    "    ]\n",
    "\n",
    "    # Write to the CSV file\n",
    "    with open(output_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        for item in results:\n",
    "            row = {\n",
    "                'name': item['name'],\n",
    "                'business_status': item['business_status'],\n",
    "                'formatted_address': item['formatted_address'],\n",
    "                'latitude': item['geometry']['location']['lat'],\n",
    "                'longitude': item['geometry']['location']['lng'],\n",
    "                'rating': item.get('rating', 'N/A'),\n",
    "                'user_ratings_total': item.get('user_ratings_total', 'N/A')\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'museum-data.txt'\n",
    "output_file_path = 'museum_data.csv'\n",
    "convert_json_to_csv(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1b990-c64e-41d0-a657-3b00b71dbe2e",
   "metadata": {},
   "source": [
    "## Generating date data for user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "868a5136-6494-4a8f-94ec-a83f73eb2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14bc8808-98c2-48ce-91d2-7561eb147cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'tableau-data/user-data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "num_rows = data.shape[0]\n",
    "chunks = np.random.randint(10, 16, size=(num_rows // 10) + 1)\n",
    "date_range = pd.date_range(start='2023-01-01', periods=len(chunks), freq='D')\n",
    "\n",
    "expanded_dates = np.repeat(date_range, chunks)[:num_rows]\n",
    "formatted_dates = pd.to_datetime(expanded_dates).strftime('%d/%m/%Y')\n",
    "\n",
    "data['date'] = formatted_dates\n",
    "\n",
    "output_file_path = 'tableau-data/user-data.csv'\n",
    "data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e143c90-0600-41ca-a01b-0644839d2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tableau-data/user-data.csv')\n",
    "df['date'] = np.random.permutation(df['date'])\n",
    "df.to_csv('tableau-data/user-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee4095b4-a255-4781-bbb5-ce695ebf7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path ='tableau-data/user-data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "num_rows = data.shape[0]\n",
    "\n",
    "weights = [0.02]*6 + [0.03]*6 + [0.04]*6 + [0.15]*6\n",
    "weights_normalized = [weight/sum(weights) for weight in weights]\n",
    "\n",
    "hours = np.random.choice(a=[*range(24)], size=num_rows, p=weights_normalized)\n",
    "minutes = np.random.randint(0, 60, size=num_rows)\n",
    "evening_timestamps = [\"{:02d}:{:02d}\".format(h, m) for h, m in zip(hours, minutes)]\n",
    "\n",
    "data['evening_timestamp'] = evening_timestamps\n",
    "data.to_csv('tableau-data/user-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba062792-8761-4630-9ce1-0804cf087c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
