{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af33727e-2639-4761-81da-42d0c1cea16d",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Visualization in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd7d026-e664-478d-bf53-66c2059b470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810da7c-5dd3-408d-ba20-5896a78ee009",
   "metadata": {},
   "source": [
    "Meetup Data from Json to Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e90b475-6dde-4383-baac-089fca49d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file\n",
    "with open('meetup-20240407.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define the CSV file where the output must be stored\n",
    "csv_file = open('event.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Assuming that data is a list of dictionaries\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        # Writing headers of CSV file\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    # Check if '_id' is in the dictionary and format it\n",
    "    if '_id' in item and '$oid' in item['_id']:\n",
    "        item['_id'] = item['_id']['$oid']\n",
    "    # Writing data of CSV file\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c86378-f125-4517-9c6e-3484994828c2",
   "metadata": {},
   "source": [
    "Posts from Json to Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645cfa3e-42e9-4e9c-bbd7-c4e1eb460758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('post-20240407.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('post.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9f8d1-47c2-49a9-a7b6-c4afb3ebed95",
   "metadata": {},
   "source": [
    "second post data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26653c7e-1846-49a8-9e6a-a4f3251d32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('system_data.postd_ata.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('1post.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    if '_id' in item and '$oid' in item['_id']:\n",
    "        item['_id'] = item['_id']['$oid']\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42576e-1b47-4e99-95f9-74e885c97390",
   "metadata": {},
   "outputs": [],
   "source": [
    "user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a45d1ba-1c1d-47f5-8f27-eb42946eea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('system_data.user_info.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_file = open('user-data.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "count = 0\n",
    "for item in data:\n",
    "    if count == 0:\n",
    "        header = item.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    "    if '_id' in item and '$oid' in item['_id']:\n",
    "        item['_id'] = item['_id']['$oid']\n",
    "    csv_writer.writerow(item.values())\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1f2dd-512f-472a-97c4-b6cb934014de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7983ebab-ff7e-45fd-a0ed-09c4c052a9df",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-bdeecce33b74>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-bdeecce33b74>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def convert_txt_to_csv('gym-data.txt', 'gym-data1.csv', delimiter=','):\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def convert_txt_to_csv('gym-data.txt', 'gym-data1.csv', delimiter=','):\n",
    "\n",
    "    df = pd.read_csv('gym-data.txt', delimiter=delimiter)\n",
    "    df.to_csv('gym-data1.csv', index=False)\n",
    "\n",
    "convert_txt_to_csv('gym-data.txt', 'gym-data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c05a72-7a44-4bf0-b32c-a8ed0cf4270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "647f03e1-c394-498f-a4df-8bfcd43286ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Decode Error: Extra data: line 73 column 2 (char 2558)\n",
      "Error context (100 characters around error):       \"user_ratings_total\" : 93\n",
      "      },\n",
      "      {\n",
      "         \"business_status\" : \"OPERATIONAL\",\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "def clean_json_string(raw_json):\n",
    "    \"\"\"\n",
    "    Decodes HTML entities and attempts to correct common JSON formatting issues.\n",
    "    \"\"\"\n",
    "    # Decode HTML entities in the JSON string\n",
    "    decoded_json = html.unescape(raw_json)\n",
    "    # Remove embedded HTML tags and fix links\n",
    "    decoded_json = re.sub(r'\\\\u003c[a-zA-Z\\/][^>]*\\\\u003e', '', decoded_json)\n",
    "    # Standard JSON clean-up steps\n",
    "    decoded_json = decoded_json.replace('\\\\\"', '\"')\n",
    "    decoded_json = decoded_json.replace('\\\\n', '')\n",
    "    decoded_json = decoded_json.replace('\\\\\\\\', '\\\\')\n",
    "    decoded_json = re.sub(r'\\\\', '', decoded_json)\n",
    "    decoded_json = re.sub(r'\\}\\s*\\{', '},{', decoded_json)\n",
    "    decoded_json = re.sub(r'\\s*,\\s*}', '}', decoded_json)\n",
    "    decoded_json = re.sub(r'\\s*,\\s*\\]', ']', decoded_json)\n",
    "    return decoded_json\n",
    "\n",
    "def extract_json_data(filepath):\n",
    "    \"\"\"\n",
    "    Extracts and cleans JSON data from a file, managing non-JSON headers and complex structures.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "        # Find the start of the actual JSON object\n",
    "        json_start_pos = content.find('{')\n",
    "        if json_start_pos == -1:\n",
    "            print(\"No JSON object found in the file.\")\n",
    "            return None\n",
    "        # Extract and clean the JSON part\n",
    "        json_content = content[json_start_pos:]\n",
    "        clean_content = clean_json_string(json_content)\n",
    "        # Try parsing the cleaned content\n",
    "        return json.loads(clean_content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        error_position = e.pos\n",
    "        print(\"Error context (100 characters around error):\", json_content[max(0, error_position-50):error_position+50])\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_json_to_csv(json_data, output_csv_path):\n",
    "    \"\"\"\n",
    "    Converts JSON data to CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle both single dict and list of dicts\n",
    "        if isinstance(json_data, dict):\n",
    "            json_data = [json_data]\n",
    "        df = pd.json_normalize(json_data)\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Data successfully saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting JSON to CSV: {e}\")\n",
    "\n",
    "# Usage\n",
    "json_data = extract_json_data('gym-data.txt')  # Replace with your actual file path\n",
    "if json_data:\n",
    "    convert_json_to_csv(json_data, 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4725a7b9-8030-4c38-98b2-ed9e9b081acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_json_string(raw_json):\n",
    "    \"\"\"\n",
    "    Performs comprehensive cleaning of the JSON string, addressing multiple potential issues.\n",
    "    \"\"\"\n",
    "    # Decode HTML entities and remove embedded HTML-like content\n",
    "    decoded_json = html.unescape(raw_json)\n",
    "    decoded_json = re.sub(r'\\\\u003c[a-zA-Z\\/][^>]*\\\\u003e', '', decoded_json)\n",
    "    \n",
    "    # Fix common escape sequence issues and backslash problems\n",
    "    decoded_json = decoded_json.replace('\\\\\"', '\"')\n",
    "    decoded_json = decoded_json.replace('\\\\n', '')\n",
    "    decoded_json = decoded_json.replace('\\\\\\\\', '\\\\')\n",
    "    decoded_json = re.sub(r'\\\\', '', decoded_json)\n",
    "\n",
    "    # Correct multiple JSON objects and add commas if needed between them\n",
    "    decoded_json = re.sub(r'(?<=\\})\\s*(?=\\{)', '},{', decoded_json)\n",
    "\n",
    "    # Handle trailing non-JSON content by ending at the last valid JSON character\n",
    "    last_brace_pos = decoded_json.rfind('}')\n",
    "    if last_brace_pos != -1:\n",
    "        decoded_json = decoded_json[:last_brace_pos + 1]\n",
    "\n",
    "    # Ensure the entire content is treated as an array of objects\n",
    "    return '[' + decoded_json + ']'\n",
    "\n",
    "def extract_json_data(filepath):\n",
    "    \"\"\"\n",
    "    Extracts and cleans JSON data from a file, ensuring valid format and structure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Find the start of actual JSON data (first '{') and remove non-JSON headers\n",
    "        json_start_pos = content.find('{')\n",
    "        if json_start_pos == -1:\n",
    "            print(\"No JSON object found in the file.\")\n",
    "            return None\n",
    "        \n",
    "        json_content = content[json_start_pos:]\n",
    "        clean_content = clean_json_string(json_content)\n",
    "        return json.loads(clean_content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        error_position = e.pos\n",
    "        print(\"Error context (100 characters around error):\", clean_content[max(0, error_position-50):error_position+50])\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_json_to_csv(json_data, output_csv_path):\n",
    "    \"\"\"\n",
    "    Converts JSON data to a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.json_normalize(json_data)\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Data successfully saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting JSON to CSV: {e}\")\n",
    "\n",
    "# Usage\n",
    "json_data = extract_json_data('gym-data.txt')  # Update with your actual file path\n",
    "if json_data:\n",
    "    convert_json_to_csv(json_data, 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18504e5e-f8b8-4b7f-9fac-6672d030c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Data Preview: [\n",
      "    {\n",
      "        \"html_attributions\": [],\n",
      "        \"next_page_token\": \"ATplDJYU7B4BzbYcu8_u-2yZD9NiT_jVyKjx_AkARe0dJUj27cCTjIk0ei9OX095kw3hd5tbjJiKZsWzJZgBP_nN4sgq4A8qv58B2gURy59d409nBDF6qjud9PvZkLmYdFZdzGHIgMPIS3xvz3bTseg7HTdTelBBoFkmp9Mo4ciLE9QPkEEYxtmsFtywheoO4ZY_Av4s1oDpf2z7f8ZT1osIdt7UvhH7tlBGeiSbIQ-6YCAxZv7sX6Sk8qxdykmrz8yZW2lL4lztJ3RLiaZKWavYnbo1VuY1hvaBwJPW3mYx9KCltVuKk_BK6p6pnkU1eJ8bZe5ykqlw4xrNhxoSAFv9-nbEyNLwLLsnsQlz3P6HWyxHxOJP1_wA4Weok3yuK49MbyhM_jWnXP32c49St3o\",\n",
      "        \"results\": [\n",
      "\n",
      "DataFrame Preview:   html_attributions                                    next_page_token  \\\n",
      "0                []  ATplDJYU7B4BzbYcu8_u-2yZD9NiT_jVyKjx_AkARe0dJU...   \n",
      "\n",
      "                                             results status  \n",
      "0  [{'business_status': 'OPERATIONAL', 'formatted...     OK  \n",
      "Data successfully saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_json_string(raw_json):\n",
    "    \"\"\"\n",
    "    Cleans JSON string by decoding HTML entities, removing HTML-like content,\n",
    "    and ensuring proper formatting for multiple JSON objects.\n",
    "    \"\"\"\n",
    "    decoded_json = html.unescape(raw_json)\n",
    "    decoded_json = re.sub(r'\\\\u003c[a-zA-Z\\/][^>]*\\\\u003e', '', decoded_json)\n",
    "    decoded_json = decoded_json.replace('\\\\\"', '\"')\n",
    "    decoded_json = decoded_json.replace('\\\\n', '')\n",
    "    decoded_json = decoded_json.replace('\\\\\\\\', '\\\\')\n",
    "    decoded_json = re.sub(r'\\\\', '', decoded_json)\n",
    "    decoded_json = re.sub(r'(?<=\\})\\s*(?=\\{)', '},{', decoded_json)\n",
    "    last_brace_pos = decoded_json.rfind('}')\n",
    "    if last_brace_pos != -1:\n",
    "        decoded_json = decoded_json[:last_brace_pos + 1]\n",
    "    return '[' + decoded_json + ']'\n",
    "\n",
    "def extract_json_data(filepath):\n",
    "    \"\"\"\n",
    "    Extracts and cleans JSON data from a file, ensuring valid format and structure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.read()\n",
    "        json_start_pos = content.find('{')\n",
    "        if json_start_pos == -1:\n",
    "            print(\"No JSON object found in the file.\")\n",
    "            return None\n",
    "        json_content = content[json_start_pos:]\n",
    "        clean_content = clean_json_string(json_content)\n",
    "        json_data = json.loads(clean_content)\n",
    "        print(\"JSON Data Preview:\", json.dumps(json_data, indent=4, sort_keys=True)[:500])  # Preview the first 500 characters of the JSON data\n",
    "        return json_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        error_position = e.pos\n",
    "        print(\"Error context (100 characters around error):\", clean_content[max(0, error_position-50):error_position+50])\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_json_to_csv(json_data, output_csv_path):\n",
    "    \"\"\"\n",
    "    Converts JSON data to a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.json_normalize(json_data)\n",
    "        print(\"DataFrame Preview:\", df.head())  # Preview the first few rows of the DataFrame\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Data successfully saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting JSON to CSV: {e}\")\n",
    "\n",
    "# Usage\n",
    "json_data = extract_json_data('gym-data.txt')  # Replace with your actual file path\n",
    "if json_data:\n",
    "    convert_json_to_csv(json_data, 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b76c713-3afc-411c-9324-9f003f3f2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_csv(input_file_path, output_file_path):\n",
    "    # Reading the entire text file to extract the JSON data\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        full_content = file.read()\n",
    "\n",
    "    # Extracting the JSON part of the text\n",
    "    json_start_index = full_content.find('{')\n",
    "    json_end_index = full_content.rfind('}') + 1  # +1 to include the last curly brace\n",
    "    json_data = full_content[json_start_index:json_end_index]\n",
    "\n",
    "    # Converting the JSON string into a dictionary\n",
    "    json_dict = json.loads(json_data)\n",
    "    results = json_dict.get('results', [])  # 'results' should contain the list of gyms\n",
    "\n",
    "    # Fields to be included in the CSV file\n",
    "    fields = ['name', 'business_status', 'formatted_address', 'latitude', 'longitude', 'rating', 'user_ratings_total']\n",
    "\n",
    "    # Writing to CSV\n",
    "    with open(output_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        for gym in results:\n",
    "            row = {\n",
    "                'name': gym.get('name', 'N/A'),\n",
    "                'business_status': gym.get('business_status', 'N/A'),\n",
    "                'formatted_address': gym.get('formatted_address', 'N/A'),\n",
    "                'latitude': gym.get('geometry', {}).get('location', {}).get('lat', 'N/A'),\n",
    "                'longitude': gym.get('geometry', {}).get('location', {}).get('lng', 'N/A'),\n",
    "                'rating': gym.get('rating', 'N/A'),\n",
    "                'user_ratings_total': gym.get('user_ratings_total', 'N/A')\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Example usage of the function\n",
    "input_file_path = 'gym-data.txt'  # Change this to your actual file path\n",
    "output_file_path = 'output_csv_file.csv'\n",
    "convert_json_to_csv(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1dfea-79e3-44ae-ad35-6944b7f767ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "museum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c888c676-8011-4a95-908c-568e44c0432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON: Extra data: line 61 column 8 (char 2053)\n"
     ]
    }
   ],
   "source": [
    "def convert_json_to_csv(input_file_path, output_file_path):\n",
    "    # Open the input file and read the data\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    # Try to find the JSON object starting and ending points\n",
    "    start_index = data.find('{')\n",
    "    end_index = data.rfind('}') + 1  # Include the last curly brace\n",
    "    \n",
    "    # Extract the JSON substring\n",
    "    json_data = data[start_index:end_index]\n",
    "\n",
    "    # Attempt to parse the JSON data\n",
    "    try:\n",
    "        parsed_json = json.loads(json_data)\n",
    "        results = parsed_json.get('results', [])\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON:\", e)\n",
    "        return\n",
    "\n",
    "    # Define the fields to be included in the CSV\n",
    "    fields = [\n",
    "        'name', 'business_status', 'formatted_address', 'latitude', 'longitude',\n",
    "        'rating', 'user_ratings_total'\n",
    "    ]\n",
    "\n",
    "    # Write to the CSV file\n",
    "    with open(output_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        for item in results:\n",
    "            row = {\n",
    "                'name': item['name'],\n",
    "                'business_status': item['business_status'],\n",
    "                'formatted_address': item['formatted_address'],\n",
    "                'latitude': item['geometry']['location']['lat'],\n",
    "                'longitude': item['geometry']['location']['lng'],\n",
    "                'rating': item.get('rating', 'N/A'),\n",
    "                'user_ratings_total': item.get('user_ratings_total', 'N/A')\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'museum-data.txt'\n",
    "output_file_path = 'museum_data.csv'\n",
    "convert_json_to_csv(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "010fba89-8bbd-4d99-acd3-7d139654f2ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unterminated character set at position 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ac4545084823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'museum-data.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'museum.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mconvert_json_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-ac4545084823>\u001b[0m in \u001b[0;36mconvert_json_to_csv\u001b[0;34m(input_file_path, output_file_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Clean the JSON string to fix common formatting errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcleaned_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_json_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Attempt to parse the corrected JSON structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-ac4545084823>\u001b[0m in \u001b[0;36mclean_json_content\u001b[0;34m(raw_json)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_json_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Replace improperly quoted keys and values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcorrected_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"(?<=[:{\\[,]\\s*)'([^']+)'(?=\\s*[:,\\]})\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\"\\1\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Ensure that numeric and boolean values do not get quotes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorrected_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\"\\s*([0-9]+|true|false)\\s*\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrected_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    752\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlookbehindgroups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookbehindgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlookbehindgroups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msourceget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                     raise source.error(\"unterminated character set\",\n\u001b[0m\u001b[1;32m    550\u001b[0m                                        source.tell() - here)\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"]\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: unterminated character set at position 30"
     ]
    }
   ],
   "source": [
    "def clean_json_content(raw_json):\n",
    "    # Replace improperly quoted keys and values\n",
    "    corrected_json = re.sub(r\"(?<=[:{\\[,]\\s*)'([^']+)'(?=\\s*[:,\\]})\", r'\"\\1\"', raw_json)\n",
    "    # Ensure that numeric and boolean values do not get quotes\n",
    "    corrected_json = re.sub(r'\"\\s*([0-9]+|true|false)\\s*\"', r'\\1', corrected_json)\n",
    "    # Fix unquoted keys\n",
    "    corrected_json = re.sub(r'([{,])(\\s*)(\\w+)(\\s*:\\s*)', r'\\1\"\\3\"\\4', corrected_json)\n",
    "    return corrected_json\n",
    "\n",
    "def convert_json_to_csv(input_file_path, output_file_path):\n",
    "    # Read the JSON data from the file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # Clean the JSON string to fix common formatting errors\n",
    "    cleaned_json = clean_json_content(file_content)\n",
    "    \n",
    "    # Attempt to parse the corrected JSON structure\n",
    "    try:\n",
    "        json_data = json.loads(cleaned_json)\n",
    "        museum_data = json_data['results']\n",
    "    \n",
    "        # Convert data to a DataFrame\n",
    "        df_museums = pd.DataFrame({\n",
    "            'Name': [museum['name'] for museum in museum_data],\n",
    "            'Address': [museum['formatted_address'] for museum in museum_data],\n",
    "            'Latitude': [museum['geometry']['location']['lat'] for museum in museum_data],\n",
    "            'Longitude': [museum['geometry']['location']['lng'] for museum in museum_data],\n",
    "            'Business Status': [museum['business_status'] for museum in museum_data],\n",
    "            'Rating': [museum.get('rating', None) for museum in museum_data],\n",
    "            'Total User Ratings': [museum.get('user_ratings_total', 0) for museum in museum_data]\n",
    "        })\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df_museums.to_csv(output_file_path, index=False)\n",
    "        print(f\"Data successfully written to {output_file_path}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse JSON: {e}\")\n",
    "\n",
    "# Usage\n",
    "input_path = 'museum-data.txt'\n",
    "output_path = 'museum.csv'\n",
    "convert_json_to_csv(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d13e0-ea74-480b-9fdb-f58896604d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34c7098b-f438-4a0c-b0ea-a047990a1216",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7427164c8e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'restaurant-data.txt'\u001b[0m  \u001b[0;31m# Replace with the path to your JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'restaurant.csv'\u001b[0m        \u001b[0;31m# Replace with your desired output CSV file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mconvert_json_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-7427164c8e98>\u001b[0m in \u001b[0;36mconvert_json_to_csv\u001b[0;34m(input_file_path, output_file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Parse the JSON data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Extract data to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def convert_json_to_csv(input_file_path, output_file_path):\n",
    "    # Read the JSON data from the file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Parse the JSON data\n",
    "    json_data = json.loads(file_content)\n",
    "\n",
    "    # Extract data to a DataFrame\n",
    "    restaurant_data = json_data['results']\n",
    "    df_restaurants = pd.DataFrame({\n",
    "        'Name': [restaurant['name'] for restaurant in restaurant_data],\n",
    "        'Address': [restaurant['formatted_address'] for restaurant in restaurant_data],\n",
    "        'Latitude': [restaurant['geometry']['location']['lat'] for restaurant in restaurant_data],\n",
    "        'Longitude': [restaurant['geometry']['location']['lng'] for restaurant in restaurant_data],\n",
    "        'Business Status': [restaurant['business_status'] for restaurant in restaurant_data],\n",
    "        'Rating': [restaurant.get('rating', None) for restaurant in restaurant_data],\n",
    "        'Total User Ratings': [restaurant.get('user_ratings_total', 0) for restaurant in restaurant_data]\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_restaurants.to_csv(output_file_path, index=False)\n",
    "    print(f\"Data successfully written to {output_file_path}\")\n",
    "\n",
    "# Usage\n",
    "input_path = 'restaurant-data.txt'  # Replace with the path to your JSON file\n",
    "output_path = 'restaurant.csv'        # Replace with your desired output CSV file path\n",
    "convert_json_to_csv(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17168e1f-3ca7-42dd-9b3d-fc55b692b2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
